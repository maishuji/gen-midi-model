{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09dc2154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: miditoolkit in ./.venv/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: miditok in ./.venv/lib/python3.13/site-packages (3.0.6.post1)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.13/site-packages (8.1.8)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.13/site-packages (4.57.3)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (from miditoolkit) (3.10.7)\n",
      "Requirement already satisfied: mido>=1.1.16 in ./.venv/lib/python3.13/site-packages (from miditoolkit) (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.19 in ./.venv/lib/python3.13/site-packages (from miditoolkit) (2.3.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.16.4 in ./.venv/lib/python3.13/site-packages (from miditok) (0.36.0)\n",
      "Requirement already satisfied: symusic>=0.5.0 in ./.venv/lib/python3.13/site-packages (from miditok) (0.5.9)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in ./.venv/lib/python3.13/site-packages (from miditok) (0.22.1)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.13/site-packages (from miditok) (4.67.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (9.7.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.13/site-packages (from ipywidgets) (3.0.16)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.13/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.13/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.13/site-packages (from huggingface-hub>=0.16.4->miditok) (1.2.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in ./.venv/lib/python3.13/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in ./.venv/lib/python3.13/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in ./.venv/lib/python3.13/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in ./.venv/lib/python3.13/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in ./.venv/lib/python3.13/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in ./.venv/lib/python3.13/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in ./.venv/lib/python3.13/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in ./.venv/lib/python3.13/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in ./.venv/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in ./.venv/lib/python3.13/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.2 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.14)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.13/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: pySmartDL in ./.venv/lib/python3.13/site-packages (from symusic>=0.5.0->miditok) (1.3.4)\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.13/site-packages (from symusic>=0.5.0->miditok) (4.5.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.13/site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.13/site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: pySmartDL in ./.venv/lib/python3.13/site-packages (from symusic>=0.5.0->miditok) (1.3.4)\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.13/site-packages (from symusic>=0.5.0->miditok) (4.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->miditoolkit) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib->miditoolkit) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->miditoolkit) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->transformers) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install miditoolkit miditok ipywidgets transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c9cd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import miditok\n",
    "\n",
    "# Choose a vocabulary / representation\n",
    "tokenizer = miditok.REMI()  # REMI is a good general format\n",
    "\n",
    "midi_dir = Path(\"data/train_midis\")\n",
    "token_seqs = []\n",
    "\n",
    "for midi_path in midi_dir.glob(\"*.mid\"):\n",
    "    # Pass the path directly to the tokenizer (miditok uses symusic internally)\n",
    "    tokens = tokenizer.encode(midi_path)\n",
    "    # tokens is a TokSequence or list of TokSequences for multi-track\n",
    "    if isinstance(tokens, list):\n",
    "        for track_tokens in tokens:\n",
    "            token_seqs.append(track_tokens.ids)\n",
    "    else:\n",
    "        token_seqs.append(tokens.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10545b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(284, 512)\n",
       "    (wpe): Embedding(2048, 512)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-7): 8 x GPT2Block(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=1536, nx=512)\n",
       "          (c_proj): Conv1D(nf=512, nx=512)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=2048, nx=512)\n",
       "          (c_proj): Conv1D(nf=512, nx=2048)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=284, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "vocab_size = tokenizer.vocab_size  # from miditok\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=vocab_size,\n",
    "    n_positions=2048,\n",
    "    n_ctx=2048,\n",
    "    n_layer=8,\n",
    "    n_head=8,\n",
    "    n_embd=512\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fbb49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MidiTokenDataset(Dataset):\n",
    "    def __init__(self, sequences, seq_len=1024):\n",
    "        self.sequences = sequences\n",
    "        self.seq_len = seq_len\n",
    "        self.data = []\n",
    "\n",
    "        for seq in sequences:\n",
    "            if len(seq) < 2:\n",
    "                continue\n",
    "            # break long seq into chunks\n",
    "            for i in range(0, len(seq) - 1, seq_len):\n",
    "                chunk = seq[i:i+seq_len+1]\n",
    "                if len(chunk) > 1:\n",
    "                    self.data.append(chunk)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.data[idx]\n",
    "        # pad if needed\n",
    "        if len(seq) < self.seq_len + 1:\n",
    "            pad_len = self.seq_len + 1 - len(seq)\n",
    "            seq = seq + [0] * pad_len  # assume 0 is PAD if unused\n",
    "        input_ids = torch.tensor(seq[:-1], dtype=torch.long)\n",
    "        labels = torch.tensor(seq[1:], dtype=torch.long)\n",
    "        return {\"input_ids\": input_ids, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cd69c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 203 sequences\n",
      "Vocabulary size: 284\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and dataloader\n",
    "dataset = MidiTokenDataset(token_seqs, seq_len=512)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Set training parameters\n",
    "num_epochs = 10\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} sequences\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7e678",
   "metadata": {},
   "source": [
    "## Using Hugging Face GPT2LMHeadModel-style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb6563ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "class MidiTokenDataset(Dataset):\n",
    "    def __init__(self, sequences, seq_len=1024):\n",
    "        self.sequences = sequences\n",
    "        self.seq_len = seq_len\n",
    "        self.data = []\n",
    "\n",
    "        for seq in sequences:\n",
    "            if len(seq) < 2:\n",
    "                continue\n",
    "            # break long seq into chunks\n",
    "            for i in range(0, len(seq) - 1, seq_len):\n",
    "                chunk = seq[i:i+seq_len+1]\n",
    "                if len(chunk) > 1:\n",
    "                    self.data.append(chunk)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.data[idx]\n",
    "        # pad if needed\n",
    "        if len(seq) < self.seq_len + 1:\n",
    "            pad_len = self.seq_len + 1 - len(seq)\n",
    "            seq = seq + [0] * pad_len  # assume 0 is PAD if unused\n",
    "        input_ids = torch.tensor(seq[:-1], dtype=torch.long)\n",
    "        labels = torch.tensor(seq[1:], dtype=torch.long)\n",
    "        return {\"input_ids\": input_ids, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb579bd",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2225d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | loss: 1.7604\n",
      "Epoch 1 | loss: 1.3440\n",
      "Epoch 1 | loss: 1.3440\n",
      "Epoch 2 | loss: 0.9500\n",
      "Epoch 2 | loss: 0.9500\n",
      "Epoch 3 | loss: 0.6943\n",
      "Epoch 3 | loss: 0.6943\n",
      "Epoch 4 | loss: 1.5805\n",
      "Epoch 4 | loss: 1.5805\n",
      "Epoch 5 | loss: 1.8692\n",
      "Epoch 5 | loss: 1.8692\n",
      "Epoch 6 | loss: 0.9520\n",
      "Epoch 6 | loss: 0.9520\n",
      "Epoch 7 | loss: 1.1887\n",
      "Epoch 7 | loss: 1.1887\n",
      "Epoch 8 | loss: 0.9724\n",
      "Epoch 8 | loss: 0.9724\n",
      "Epoch 9 | loss: 1.2262\n",
      "Epoch 9 | loss: 1.2262\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "model.train()\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in loader:\n",
    "        input_ids = batch[\"input_ids\"].cuda()\n",
    "        labels = batch[\"labels\"].cuda()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch} | loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a595fb47",
   "metadata": {},
   "source": [
    "## Generating new MIDI sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85553cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_tokens(model, tokenizer, max_length=1024, temperature=1.0, top_k=0, prompt=None):\n",
    "    model.eval()\n",
    "    if prompt is None:\n",
    "        # Use some default BOS token or a small generic prompt\n",
    "        prompt = [tokenizer[\"BOS_None\"]] if \"BOS_None\" in tokenizer.vocab else [0]\n",
    "\n",
    "    input_ids = torch.tensor(prompt, dtype=torch.long).unsqueeze(0).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length - len(prompt)):\n",
    "            outputs = model(input_ids=input_ids)\n",
    "            logits = outputs.logits[:, -1, :] / temperature\n",
    "\n",
    "            if top_k > 0:\n",
    "                values, indices = torch.topk(logits, top_k)\n",
    "                probs = torch.softmax(values, dim=-1)\n",
    "                next_token_idx = torch.multinomial(probs, 1)\n",
    "                next_token = indices.gather(1, next_token_idx)\n",
    "            else:\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                next_token = torch.multinomial(probs, 1)\n",
    "\n",
    "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "\n",
    "    return input_ids[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcb88eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using prompt: ['Bar_None', 'Bar_None', 'Position_0', 'Pitch_67', 'Velocity_63', 'Duration_1.4.8', 'Position_12', 'Pitch_66', 'Velocity_63', 'Duration_0.2.8', 'Position_14', 'Pitch_67', 'Velocity_63', 'Duration_0.2.8', 'Position_16', 'Pitch_66', 'Velocity_63', 'Duration_1.0.8', 'Position_24', 'Pitch_62']\n",
      "Generated MIDI saved to output_generated.mid\n",
      "Duration: 3.50 seconds (approximate)\n"
     ]
    }
   ],
   "source": [
    "# Generate new MIDI with a proper prompt from training data\n",
    "from miditok import TokSequence\n",
    "\n",
    "# Use the beginning of a real sequence as a prompt\n",
    "prompt_seq = token_seqs[0][:20]  # First 20 tokens from first training sequence\n",
    "print(f\"Using prompt: {[tokenizer[tid] for tid in prompt_seq]}\")\n",
    "\n",
    "# Increase max_length for longer music (1536 tokens should give ~10-15 seconds)\n",
    "generated_tokens = generate_tokens(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    max_length=1536,  # Increased from 512 for longer output\n",
    "    temperature=0.9, \n",
    "    top_k=50,\n",
    "    prompt=prompt_seq\n",
    ")\n",
    "\n",
    "# Convert token IDs to token strings\n",
    "token_strings = [tokenizer[token_id] for token_id in generated_tokens]\n",
    "\n",
    "# Create TokSequence with both IDs and token strings\n",
    "tok_seq = TokSequence(ids=generated_tokens, tokens=token_strings)\n",
    "\n",
    "# Convert tokens back to MIDI (wrap in a list for multi-track support)\n",
    "generated_midi = tokenizer.decode([tok_seq])\n",
    "generated_midi.dump_midi(\"output_generated.mid\")\n",
    "print(f\"Generated MIDI saved to output_generated.mid\")\n",
    "print(f\"Duration: {generated_midi.end() / generated_midi.ticks_per_quarter / 2:.2f} seconds (approximate)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "129e02c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tracks: 1\n",
      "Time division (ticks per quarter note): 8\n",
      "Duration: 56.00 ticks\n",
      "Duration in seconds (at 120 BPM): 3.50s\n",
      "\n",
      "Track 0:\n",
      "  Notes: 4\n",
      "  Name: Acoustic Grand Piano\n",
      "  First 3 notes: [Note(32, 12, 67, 63, 'Tick'), Note(44, 2, 66, 63, 'Tick'), Note(46, 2, 67, 63, 'Tick')]\n",
      "  Last 3 notes: [Note(44, 2, 66, 63, 'Tick'), Note(46, 2, 67, 63, 'Tick'), Note(48, 8, 66, 63, 'Tick')]\n",
      "\n",
      "Generated 1536 tokens\n",
      "First 20 tokens: [4, 4, 190, 51, 109, 137, 202, 50, 109, 127, 204, 51, 109, 127, 206, 50, 109, 133, 214, 46]\n",
      "First 20 token strings: ['Bar_None', 'Bar_None', 'Position_0', 'Pitch_67', 'Velocity_63', 'Duration_1.4.8', 'Position_12', 'Pitch_66', 'Velocity_63', 'Duration_0.2.8', 'Position_14', 'Pitch_67', 'Velocity_63', 'Duration_0.2.8', 'Position_16', 'Pitch_66', 'Velocity_63', 'Duration_1.0.8', 'Position_24', 'Pitch_62']\n",
      "\n",
      "Last 20 tokens: [127, 41, 127, 41, 127, 53, 127, 4, 41, 127, 34, 127, 63, 127, 41, 127, 41, 127, 50, 127]\n",
      "Last 20 token strings: ['Duration_0.2.8', 'Pitch_57', 'Duration_0.2.8', 'Pitch_57', 'Duration_0.2.8', 'Pitch_69', 'Duration_0.2.8', 'Bar_None', 'Pitch_57', 'Duration_0.2.8', 'Pitch_50', 'Duration_0.2.8', 'Pitch_79', 'Duration_0.2.8', 'Pitch_57', 'Duration_0.2.8', 'Pitch_57', 'Duration_0.2.8', 'Pitch_66', 'Duration_0.2.8']\n",
      "\n",
      "Token type distribution:\n",
      "  Duration: 610\n",
      "  Pitch: 582\n",
      "  Velocity: 237\n",
      "  Position: 87\n",
      "  Bar: 18\n",
      "  PitchDrum: 2\n"
     ]
    }
   ],
   "source": [
    "# Check the generated MIDI file\n",
    "print(f\"Number of tracks: {len(generated_midi.tracks)}\")\n",
    "print(f\"Time division (ticks per quarter note): {generated_midi.ticks_per_quarter}\")\n",
    "print(f\"Duration: {generated_midi.end():.2f} ticks\")\n",
    "print(f\"Duration in seconds (at 120 BPM): {generated_midi.end() / generated_midi.ticks_per_quarter / 2:.2f}s\")\n",
    "\n",
    "for i, track in enumerate(generated_midi.tracks):\n",
    "    print(f\"\\nTrack {i}:\")\n",
    "    print(f\"  Notes: {len(track.notes)}\")\n",
    "    print(f\"  Name: {track.name}\")\n",
    "    if len(track.notes) > 0:\n",
    "        print(f\"  First 3 notes: {track.notes[:3]}\")\n",
    "        print(f\"  Last 3 notes: {track.notes[-3:]}\")\n",
    "    else:\n",
    "        print(\"  WARNING: This track has no notes!\")\n",
    "        \n",
    "# Check the generated tokens\n",
    "print(f\"\\nGenerated {len(generated_tokens)} tokens\")\n",
    "print(f\"First 20 tokens: {generated_tokens[:20]}\")\n",
    "print(f\"First 20 token strings: {token_strings[:20]}\")\n",
    "\n",
    "# Check for early stopping tokens\n",
    "print(f\"\\nLast 20 tokens: {generated_tokens[-20:]}\")\n",
    "print(f\"Last 20 token strings: {token_strings[-20:]}\")\n",
    "\n",
    "# Count token types\n",
    "import collections\n",
    "token_type_counts = collections.Counter([t.split('_')[0] for t in token_strings])\n",
    "print(f\"\\nToken type distribution:\")\n",
    "for token_type, count in token_type_counts.most_common(10):\n",
    "    print(f\"  {token_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67de40ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common tokens in training data:\n",
      "  109: Velocity_63 (count: 90)\n",
      "  4: Bar_None (count: 54)\n",
      "  127: Duration_0.2.8 (count: 39)\n",
      "  190: Position_0 (count: 33)\n",
      "  233: PitchDrum_38 (count: 24)\n",
      "  126: Duration_0.1.8 (count: 24)\n",
      "  140: Duration_1.7.8 (count: 17)\n",
      "  206: Position_16 (count: 14)\n",
      "  101: Velocity_31 (count: 12)\n",
      "  214: Position_24 (count: 11)\n",
      "  51: Pitch_67 (count: 10)\n",
      "  156: Duration_3.7.8 (count: 10)\n",
      "  32: Pitch_48 (count: 9)\n",
      "  113: Velocity_79 (count: 9)\n",
      "  129: Duration_0.4.8 (count: 8)\n",
      "  38: Pitch_54 (count: 8)\n",
      "  202: Position_12 (count: 7)\n",
      "  133: Duration_1.0.8 (count: 7)\n",
      "  46: Pitch_62 (count: 7)\n",
      "  198: Position_8 (count: 7)\n",
      "\n",
      "Checking for Program tokens in vocabulary:\n"
     ]
    }
   ],
   "source": [
    "# Check what tokens are in the training data\n",
    "import collections\n",
    "all_tokens = []\n",
    "for seq in token_seqs[:5]:  # Check first 5 sequences\n",
    "    all_tokens.extend(seq[:100])  # First 100 tokens of each\n",
    "\n",
    "# Get token frequencies\n",
    "token_counts = collections.Counter(all_tokens)\n",
    "print(\"Most common tokens in training data:\")\n",
    "for token_id, count in token_counts.most_common(20):\n",
    "    print(f\"  {token_id}: {tokenizer[token_id]} (count: {count})\")\n",
    "    \n",
    "# Check if we have program tokens\n",
    "print(\"\\nChecking for Program tokens in vocabulary:\")\n",
    "for token_name in list(tokenizer.vocab.keys())[:30]:\n",
    "    if 'Program' in token_name or 'Instrument' in token_name:\n",
    "        print(f\"  Found: {token_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed223d15",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "**Current Issues:**\n",
    "- Model generated 1536 tokens but only 4 valid notes (~3.5 seconds)\n",
    "- Last tokens show the model is stuck in a loop: `Pitch → Duration → Pitch → Duration`\n",
    "- Missing `Position` and `Velocity` tokens needed to complete note sequences\n",
    "- In REMI, a valid note needs: Position → Pitch → Velocity → Duration\n",
    "\n",
    "**Why this happened:**\n",
    "- Only trained for 10 epochs on 8 MIDI files (very small dataset)\n",
    "- Model hasn't learned proper token sequence structure\n",
    "- Training loss was still decreasing (1.76 → 1.23), indicating it needs more training\n",
    "\n",
    "**How to get longer, better music:**\n",
    "\n",
    "1. **Train longer**: 50-100 epochs instead of 10\n",
    "2. **More training data**: Add more MIDI files to `data/train_midis/`\n",
    "3. **Use a pre-trained model**: Start with a model that already understands music structure\n",
    "4. **Post-process tokens**: Filter out invalid token sequences before decoding\n",
    "\n",
    "For now, your setup works and can generate MIDI! The model just needs more training to create longer, more coherent sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0f544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
